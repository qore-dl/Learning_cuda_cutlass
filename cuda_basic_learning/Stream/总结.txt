6.6 总结

流的概念是 CUDA 编程模型的一个基本组成部分。允许高级 CUDA 操作在独立的流中排队执行，
CUDA 流可以实现粗粒度并发。因为 CUDA 支持异步操作和大多数版本的 runtime 函数，
所以它可以在多个 CUDA 流之间调度计算和通信。

从概念上讲，如果 CUDA 操作之间存在依赖关系，则它们必须在同一个流中被调度。
例如，为了确保应用程序的准确无误，内核必须在同一流中被调度，并在它使用的数据进行传输完成后执行。
另外，没有依赖关系的操作可以在任意的流中被调度。
在 CUDA 中，通常可以用 3 种不同类型的重叠方案来隐藏计算或通信延迟：
1. 在设备上重叠多个并发的 kernel；
2. 重叠带有传入或传出设备数据传输的 CUDA 内核；
3. 重叠 CPU 执行 和 GPU 执行 

为了充分利用设备，并确保最大的并发性，还需要注意以下的问题：
1. 平衡内核资源需求和并发资源需求。在设备上一次启动过多的计算任务，可能会导致内核串行，
这会使得硬件资源的工作快变得空闲。
但是，也需要确保设备没有被充分利用，一直有工作在排队等待执行。

2. 如果可能的话，避免使用默认流执行异步操作。
放置在默认流中的操作可能会阻塞其他非默认的 CUDA 流的进展。

3. 在 Fermi 设备上，从深度优先和广度优先两方面考虑主机的调度。
这个选择可以通过消除共享硬件工作队列上的虚假依赖关系，显著影响其性能。

4. 要注意隐式同步的函数，并且充分利用它们和异步函数来避免性能的降低。

此外，本章还介绍了 CUDA 可视化性能分析器（nvvp）在可视化 GPU 执行中的作用。
nvvp 允许确认操作重叠的条件，并且易于多个流行为的可视化。